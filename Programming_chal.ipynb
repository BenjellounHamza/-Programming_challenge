{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Programming challenge",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU2UWplh-M10"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "from sklearn import decomposition\n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
        "from numpy import loadtxt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import csv"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KM5Gp55e-TyF"
      },
      "source": [
        "**Clean training data set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0wkD0Gz6Rg-"
      },
      "source": [
        "train = pd.read_csv('TrainOnMe.csv')\n",
        "test = pd.read_csv('EvaluateOnMe.csv')\n",
        "\n",
        "#drop id column\n",
        "train.pop('id')\n",
        "test.pop(test.columns[0])\n",
        "\n",
        "# remove None values from training and test set.\n",
        "train = train.dropna()\n",
        "test = test.dropna()\n",
        "\n",
        "# remove rows that have ?\n",
        "train = train.drop(train[train.values  == '?'].index)\n",
        "test = test.drop(test[test.values  == '?'].index)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlN42WQnHxau"
      },
      "source": [
        "*Data encoded with OneHotEncoder*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXvuzyWrHwNf"
      },
      "source": [
        "train_onehot = pd.get_dummies(train, columns = ['x5', 'x6'])\n",
        "test_onehot = pd.get_dummies(test, columns = ['x5', 'x6'])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHv10AsjIDXm"
      },
      "source": [
        "*Data encoded with label LabelEncoder*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2yybhk-ICRg"
      },
      "source": [
        "le = preprocessing.LabelEncoder()\n",
        "train_LabelEncode = train.copy()\n",
        "\n",
        "le.fit(train_LabelEncode['x5'])\n",
        "train_LabelEncode['x5'] = le.transform(train['x5'])\n",
        "\n",
        "le.fit(train_LabelEncode['x6'])\n",
        "train_LabelEncode['x6'] = le.transform(train_LabelEncode['x6'])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXU8mXSQPXKV"
      },
      "source": [
        "*Choose between the two ways of encoding*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UczigfuhJRoA"
      },
      "source": [
        "#train = train_LabelEncode\n",
        "train = train_onehot\n",
        "y = train.pop('y')\n",
        "\n",
        "test = test_onehot"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c548NCf3-d4j"
      },
      "source": [
        "\n",
        "\n",
        "**Random forest classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6IjM0BZ-6li",
        "outputId": "b251fa9b-2ea2-450f-82a6-8046c865b3a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "classifier_random_forest = RandomForestClassifier(n_estimators= 150)\n",
        "scores = cross_val_score(classifier_random_forest, train, y, cv=10)\n",
        "print(\"random forest accuracy = \", scores.mean())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "random forest accuracy =  0.8513333333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtPTLmV5_ULY"
      },
      "source": [
        "**Gradient Boosting Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixcrCgcg_U62",
        "outputId": "427b40c4-fe66-4957-a73e-6542ff1f1583",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "classifier_gradient = GradientBoostingClassifier(n_estimators= 1000)\n",
        "scores = cross_val_score(classifier_gradient, train, y, cv=10)\n",
        "print(\"gradient boosting accuracy = \", scores.mean())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gradient boosting accuracy =  0.8733535353535353\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtARwZNn4E58"
      },
      "source": [
        "# classifier_random_forest = GradientBoostingClassifier()\n",
        "# parameters = [{'n_estimators' : [500, 100, 50], 'max_depth' : [10, 20, 30 , None]}]\n",
        "# rand_search = GridSearchCV(estimator = classifier_random_forest,\n",
        "#                            param_grid = parameters,\n",
        "#                            scoring = 'accuracy',\n",
        "#                            cv = 2,\n",
        "#                            n_jobs = -1)\n",
        "# rand_search = grid_search.fit(train, y)\n",
        "# accuracy = rand_search.best_score_\n",
        "# rand_search.best_params_"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wk11qlAqhwQQ"
      },
      "source": [
        "**Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmGnn-dOh0np"
      },
      "source": [
        "X_train_NN = train.copy()\n",
        "# normalization:\n",
        "\n",
        "scale = StandardScaler(with_mean=0, with_std=1)\n",
        "scale.fit(X_train_NN, y)\n",
        "X_train_NN = scale.transform(X_train_NN)\n",
        "X_train_NN = np.asarray(train).astype('float64')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-Rah_3reMwu",
        "outputId": "29a255cc-98d2-4227-9676-2c4306d47970",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "\n",
        "def create_model():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(17, input_dim=17, activation='relu'))\n",
        "  model.add(Dense(50, activation='sigmoid'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(3, activation='softmax'))\n",
        "  model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "classifier_NN = KerasClassifier(build_fn=create_model, \n",
        "                                 epochs=200, \n",
        "                                 batch_size=50, \n",
        "                                 verbose=0)\n",
        "scores = cross_val_score(classifier_NN, X_train_NN, y, cv=10)\n",
        "print(\"NN accuracy = \", scores.mean())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x7f42c18940d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f42cb815e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f42c2a1da60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f42c100b730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f42c1fac8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f42c1f23ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "NN accuracy =  0.8402828276157379\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPUvKklQbf7Y"
      },
      "source": [
        "KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFBJWqykbegx",
        "outputId": "36f7fdde-8c02-4fef-9486-81700213abe3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Create the knn model.\n",
        "classifier_KNN = KNeighborsClassifier(n_neighbors = 15)\n",
        "scores = cross_val_score(classifier_KNN, train, y, cv=10)\n",
        "print(\"KNN accuracy = \", scores.mean())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNN accuracy =  0.8272121212121212\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fpAKnaIPgFA"
      },
      "source": [
        "\n",
        "\n",
        "**Vote of different models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ctf-Bq7jGdB"
      },
      "source": [
        "#train all models\n",
        "classifier_gradient.fit(train, y)\n",
        "y_gradient = classifier_gradient.predict(test)\n",
        "\n",
        "classifier_random_forest.fit(train, y)\n",
        "y_random_forest = classifier_random_forest.predict(test)\n",
        "\n",
        "classifier_NN.fit(train.astype('float64'), y)\n",
        "y_NN = classifier_NN.predict(test.astype('float64'))\n",
        "\n",
        "classifier_KNN.fit(train, y)\n",
        "y_KNN = classifier_KNN.predict(test)\n",
        "\n",
        "#vote\n",
        "y_pred = []\n",
        "for i in range(len(y)):\n",
        "  ys = [y_gradient[i], y_random_forest[i], y_NN[i], y_KNN[i]]\n",
        "  y_pred.append(max(set(ys), key = ys.count))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiXjMgdMN7lG"
      },
      "source": [
        "**Final model : Gradient boosting classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBWcIBqJN69W"
      },
      "source": [
        "classifier_gradient = GradientBoostingClassifier(n_estimators= 1000)\n",
        "classifier_gradient.fit(train, y)\n",
        "y_classes = classifier_gradient.predict(test)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iD1I07CXGwT-"
      },
      "source": [
        "**List to CSV**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khjrICfpGvyY"
      },
      "source": [
        "pd.DataFrame(y_classes).to_csv(\"105990.txt\", header = False, index = False)"
      ],
      "execution_count": 14,
      "outputs": []
    }
  ]
}